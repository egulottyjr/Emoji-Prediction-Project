{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "XOpT_bu5WPex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "gBp3kxCNCw9G"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VUvUvC5arxx",
        "outputId": "0ecfc067-eeca-48b0-e98d-8c2bc3ceaff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.11.1)\n"
          ]
        }
      ],
      "source": [
        "pip install emoji"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing"
      ],
      "metadata": {
        "id": "JL8CpRChWTYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in the data"
      ],
      "metadata": {
        "id": "wxJs1BNpywfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data was cleaned in another file and not here just for ease and to convenience but the file used to clean this data set is also attached"
      ],
      "metadata": {
        "id": "IH36yYWVy7ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/dev_cleaned3.csv')"
      ],
      "metadata": {
        "id": "CzF0IlVw0Y6V"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into training and testing sets"
      ],
      "metadata": {
        "id": "-YnjrmLKhLkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df.dropna(subset=['emoji'], inplace=True)\n",
        "\n",
        "texts = df['text'].values\n",
        "labels = df['emoji'].apply(str).values\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "R_CEF4zyhZsH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2: Baseline: No sentiment and No LSTM"
      ],
      "metadata": {
        "id": "UpVZuEh1WnW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A lot of steps for each model are the same or repeated due to the long run time of the models, for example each model was created and ran on different days and thus imports may repeat or parts of the code may repeat because we did not run the entire file at once but instead ran each model at different times"
      ],
      "metadata": {
        "id": "eaaYnjEQiGvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# filter out NaN values\n",
        "valid_indices = [i for i, label in enumerate(y_train) if pd.notna(label)]\n",
        "filtered_texts = [X_train[i] for i in valid_indices]\n",
        "filtered_labels = [y_train[i] for i in valid_indices]\n",
        "\n",
        "# Tokenize texts\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(filtered_texts)\n",
        "sequences = tokenizer.texts_to_sequences(filtered_texts)\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=10)\n",
        "\n",
        "# Encode labels\n",
        "label_list = np.unique(filtered_labels)\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(label_list)\n",
        "encoded_labels = label_encoder.transform(filtered_labels)\n",
        "y = tf.keras.utils.to_categorical(encoded_labels, num_classes=len(label_list))\n",
        "\n",
        "\n",
        "# First baseline model- no LSTM layers\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=8, input_length=10))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(len(label_list), activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "model2.fit(X, y, epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZekhQ47CHGN",
        "outputId": "2d01735a-c2b6-4076-d08b-f70f5767e0a3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7552/7552 [==============================] - 37s 5ms/step - loss: 2.8606 - accuracy: 0.2935\n",
            "Epoch 2/10\n",
            "7552/7552 [==============================] - 26s 3ms/step - loss: 2.5419 - accuracy: 0.3512\n",
            "Epoch 3/10\n",
            "7552/7552 [==============================] - 25s 3ms/step - loss: 2.3916 - accuracy: 0.3870\n",
            "Epoch 4/10\n",
            "7552/7552 [==============================] - 27s 4ms/step - loss: 2.2814 - accuracy: 0.4139\n",
            "Epoch 5/10\n",
            "7552/7552 [==============================] - 25s 3ms/step - loss: 2.1936 - accuracy: 0.4365\n",
            "Epoch 6/10\n",
            "7552/7552 [==============================] - 25s 3ms/step - loss: 2.1209 - accuracy: 0.4548\n",
            "Epoch 7/10\n",
            "7552/7552 [==============================] - 25s 3ms/step - loss: 2.0599 - accuracy: 0.4712\n",
            "Epoch 8/10\n",
            "7552/7552 [==============================] - 25s 3ms/step - loss: 2.0079 - accuracy: 0.4852\n",
            "Epoch 9/10\n",
            "7552/7552 [==============================] - 24s 3ms/step - loss: 1.9629 - accuracy: 0.4973\n",
            "Epoch 10/10\n",
            "7552/7552 [==============================] - 24s 3ms/step - loss: 1.9243 - accuracy: 0.5082\n",
            "1888/1888 [==============================] - 4s 2ms/step\n",
            "[':face_with_tears_of_joy:' ':face_with_tears_of_joy:'\n",
            " ':face_with_tears_of_joy:' ... ':face_with_tears_of_joy:'\n",
            " ':loudly_crying_face:' ':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model 2"
      ],
      "metadata": {
        "id": "Kpzls_LOWrPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process the testing data like the training data\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_sequences, maxlen=10)\n",
        "encoded_labels_test = label_encoder.transform(y_test)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(encoded_labels_test, num_classes=len(label_list))\n",
        "\n",
        "# Predict classes and find true classes for accuracy measures\n",
        "predictions2 = model2.predict(X_test_padded)\n",
        "predicted_classes = np.argmax(predictions2, axis=1)\n",
        "true_classes = np.argmax(y_test_categorical, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWXcDwSjE06_",
        "outputId": "b66c4c29-134f-4474-9221-5c6769a32189"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1888/1888 [==============================] - 3s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originally, we were following the standford paper that uses accuracy, precision, recall, and F1 score to assess their models so we followed these steps as well but only included accuracy in our report as we were not interested in precision, recall, or F1 score."
      ],
      "metadata": {
        "id": "qzSZmjyHf-Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='weighted')\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPyIF0eMaUqN",
        "outputId": "27c82914-ed5d-4651-b59a-92a2dfd963a0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3613\n",
            "Precision: 0.3333\n",
            "Recall: 0.3613\n",
            "F1 Score: 0.3225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The follow code boxes take random sentances for the NN to predict emojis on for our peers to evalute in the testing phase"
      ],
      "metadata": {
        "id": "8YY1j-q2T34N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New test sentance\n",
        "random_sentence = \"yay\"\n",
        "\n",
        "# Tokenize and pad the sentence\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "# Predict the label\n",
        "prediction = model2.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "# Decode the predicted label\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)\n"
      ],
      "metadata": {
        "id": "0rTMKvO5Te4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bc446c-8c55-4591-cff3-aeb4b7a17b1d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted label for 'yay': [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I am so happy\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model2.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "id": "nnlSqfhIUS46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccebed8-640a-4508-949c-20e72996a1e8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted label for 'I am so happy': [':loudly_crying_face:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"Bro I am so mad\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model2.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "id": "fuTGQhv3UXoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e65678-c732-451a-b939-3e05f1b71996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted label for 'Bro I am so mad': [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I love you\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model2.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "id": "f4IRW1I-UhAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b729ecf0-dbf5-44bd-9392-ea0443719f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predicted label for 'I love you': [':red_heart:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"LMAO\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model2.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "id": "t_SC0KP4UprY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c542d95e-8a2d-4a3d-d72b-dec59a361b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted label for 'LMAO': [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3: LSTM with no sentiment"
      ],
      "metadata": {
        "id": "sAokuYs1VeCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference for bidirectional LSTMs: https://keras.io/api/layers/recurrent_layers/bidirectional/"
      ],
      "metadata": {
        "id": "5cfbZrJpk9ux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tux6jA7Tha4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9e9d4a-1953-4208-9c4a-e683571d52ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 10, 128)           6144      \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 10, 128)           98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 48)                3120      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 157488 (615.19 KB)\n",
            "Trainable params: 157488 (615.19 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "15452/15452 [==============================] - 141s 9ms/step - loss: 2.9132 - accuracy: 0.2779\n",
            "Epoch 2/10\n",
            "15452/15452 [==============================] - 128s 8ms/step - loss: 2.8373 - accuracy: 0.2917\n",
            "Epoch 3/10\n",
            "15452/15452 [==============================] - 128s 8ms/step - loss: 2.8004 - accuracy: 0.2991\n",
            "Epoch 4/10\n",
            "15452/15452 [==============================] - 126s 8ms/step - loss: 2.7747 - accuracy: 0.3042\n",
            "Epoch 5/10\n",
            "15452/15452 [==============================] - 128s 8ms/step - loss: 2.7549 - accuracy: 0.3095\n",
            "Epoch 6/10\n",
            "15452/15452 [==============================] - 130s 8ms/step - loss: 2.7394 - accuracy: 0.3131\n",
            "Epoch 7/10\n",
            "15452/15452 [==============================] - 135s 9ms/step - loss: 2.7276 - accuracy: 0.3159\n",
            "Epoch 8/10\n",
            "15452/15452 [==============================] - 129s 8ms/step - loss: 2.7170 - accuracy: 0.3186\n",
            "Epoch 9/10\n",
            "15452/15452 [==============================] - 128s 8ms/step - loss: 2.7080 - accuracy: 0.3205\n",
            "Epoch 10/10\n",
            "15452/15452 [==============================] - 134s 9ms/step - loss: 2.7004 - accuracy: 0.3224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f6902ffa470>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "max_seq_length = 10\n",
        "vocab_size = len(label_list)\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_seq_length))\n",
        "model3.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(LSTM(64))\n",
        "model3.add(Dense(len(label_list), activation='softmax'))\n",
        "\n",
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.summary()\n",
        "\n",
        "model3.fit(X, y, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model 3"
      ],
      "metadata": {
        "id": "ntJr_goDMSH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_sequences, maxlen=10)\n",
        "encoded_labels_test = label_encoder.transform(y_test)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(encoded_labels_test, num_classes=len(label_list))\n",
        "\n",
        "\n",
        "predictions2 = model3.predict(X_test_padded)\n",
        "predicted_classes = np.argmax(predictions2, axis=1)\n",
        "true_classes = np.argmax(y_test_categorical, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "lUl7pZXSLUe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='weighted')\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlGNeRPja3Vz",
        "outputId": "262cba30-9fbd-460b-b0f1-9d1b1c8aebe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3234\n",
            "Precision: 0.4291\n",
            "Recall: 0.3234\n",
            "F1 Score: 0.2428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "random_sentence = \"yay\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model3.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxAa4JoUL8GZ",
        "outputId": "2b3c81ea-cbba-4efe-a331-78f916db8b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 114ms/step\n",
            "Predicted label for 'yay': [':clapping_hands:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I am so happy\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model3.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaL1Z5npMBFO",
        "outputId": "4c09b15f-9ba5-4ebb-f892-4ce26f796130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 71ms/step\n",
            "Predicted label for 'I am so happy': [':loudly_crying_face:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"Bro I am so mad\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model3.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7LGAZ0VMFTM",
        "outputId": "b73b3ce6-fe8f-4f4f-841b-23231e23efda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted label for 'Bro I am so mad': [':loudly_crying_face:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I love you\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model3.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjN6uTI4MI60",
        "outputId": "ce014c7f-cef5-484e-99bd-4aaf68fc5e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted label for 'I love you': [':two_hearts:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"LMAO\"\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "\n",
        "prediction = model3.predict(padded_sequence)\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)\n"
      ],
      "metadata": {
        "id": "KHtOMVlGMPSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4: LSTM with sentiment"
      ],
      "metadata": {
        "id": "7APBQLsdXUw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code here makes use of the following resources to approach sentiment analysis within NN: https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91"
      ],
      "metadata": {
        "id": "qu6pwW0chN0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following refernece was used for TextBlob: https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524"
      ],
      "metadata": {
        "id": "j4wkQBi0leYn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "6HtMdV3W0qSJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from textblob import TextBlob\n",
        "import tensorflow as tf\n",
        "\n",
        "df2 = pd.read_csv('/content/dev_cleaned3.csv')\n",
        "\n",
        "def get_sentiment(text):\n",
        "    text = str(text)\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "df2['Sentiment'] = df2['text'].apply(get_sentiment)\n",
        "\n",
        "df2['Sentiment'] = (df2['Sentiment'] - df2['Sentiment'].mean()) / df2['Sentiment'].std()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df2[['text', 'Sentiment']]\n",
        "y = df2['emoji']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "JwBMIS1vfbQg"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train['text'])\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train['text'])\n",
        "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_sequences, maxlen=10)\n",
        "\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test['text'])\n",
        "X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_sequences, maxlen=10)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_train_categorical = tf.keras.utils.to_categorical(y_train_encoded, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "y_test_categorical = tf.keras.utils.to_categorical(y_test_encoded, num_classes=len(label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "DVRnsUSlf1NC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sentiment = X_train['Sentiment'].values\n",
        "X_test_sentiment = X_test['Sentiment'].values\n",
        "\n",
        "X_train_sentiment = X_train_sentiment.reshape(-1, 1)\n",
        "X_test_sentiment = X_test_sentiment.reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "4fySCGzrf5V4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "text_input = Input(shape=(10,), dtype='int32', name='text_input')\n",
        "sentiment_input = Input(shape=(1,), dtype='float32', name='sentiment_input')\n",
        "\n",
        "text_features = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100)(text_input)\n",
        "text_features = Bidirectional(LSTM(64, return_sequences=True))(text_features)\n",
        "text_features = Dropout(0.5)(text_features)\n",
        "text_features = LSTM(32)(text_features)\n",
        "text_features = Dropout(0.5)(text_features)\n",
        "\n",
        "sentiment_features = Dense(16, activation='relu')(sentiment_input)\n",
        "\n",
        "concatenated_features = concatenate([text_features, sentiment_features])\n",
        "\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(concatenated_features)\n",
        "\n",
        "model = Model(inputs=[text_input, sentiment_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit([X_train_padded, X_train_sentiment], y_train_categorical, epochs=10, validation_split=0.2)\n",
        "\n",
        "loss, accuracy = model.evaluate([X_test_padded, X_test_sentiment], y_test_categorical)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHF9T_bigJSM",
        "outputId": "71cdd95a-dcd1-4b44-b6f7-d4a79e291a3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4204/4204 [==============================] - 62s 13ms/step - loss: 2.9012 - accuracy: 0.2847 - val_loss: 2.6937 - val_accuracy: 0.3129\n",
            "Epoch 2/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 2.6097 - accuracy: 0.3302 - val_loss: 2.6147 - val_accuracy: 0.3286\n",
            "Epoch 3/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 2.4139 - accuracy: 0.3676 - val_loss: 2.6209 - val_accuracy: 0.3385\n",
            "Epoch 4/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 2.2212 - accuracy: 0.4100 - val_loss: 2.6797 - val_accuracy: 0.3448\n",
            "Epoch 5/10\n",
            "4204/4204 [==============================] - 57s 13ms/step - loss: 2.0480 - accuracy: 0.4518 - val_loss: 2.7463 - val_accuracy: 0.3526\n",
            "Epoch 6/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 1.8931 - accuracy: 0.4910 - val_loss: 2.9014 - val_accuracy: 0.3498\n",
            "Epoch 7/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 1.7666 - accuracy: 0.5256 - val_loss: 3.0298 - val_accuracy: 0.3547\n",
            "Epoch 8/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 1.6644 - accuracy: 0.5565 - val_loss: 3.1276 - val_accuracy: 0.3538\n",
            "Epoch 9/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 1.5816 - accuracy: 0.5789 - val_loss: 3.1953 - val_accuracy: 0.3583\n",
            "Epoch 10/10\n",
            "4204/4204 [==============================] - 43s 10ms/step - loss: 1.5068 - accuracy: 0.5994 - val_loss: 3.2720 - val_accuracy: 0.3600\n",
            "1314/1314 [==============================] - 5s 4ms/step - loss: 3.2917 - accuracy: 0.3562\n",
            "Test Loss: 3.2916953563690186, Test Accuracy: 0.3561878502368927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model 4"
      ],
      "metadata": {
        "id": "X77E0vKjmZd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([X_test_padded, X_test_sentiment])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "true_classes = np.argmax(y_test_categorical, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAV2QY9ev20Q",
        "outputId": "16ce9ed8-207b-42f3-f2b1-5c4e31686c78"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1314/1314 [==============================] - 6s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K80brRAwv7ro",
        "outputId": "6095ad85-e796-4189-b972-2f38baaae74d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.3562\n",
            "Precision: 0.3371\n",
            "Recall: 0.3562\n",
            "F1 Score: 0.3290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"yay\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6OO1dIewqsm",
        "outputId": "21430f39-3d55-40f3-df0a-a9705da47a91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 76ms/step\n",
            "yay [':clapping_hands:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I am so happy\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoAP9tC3xcsg",
        "outputId": "dc71eb5d-787b-40a4-f73b-10f5dfaf4cb8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n",
            "I am so happy [':loudly_crying_face:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"Bro I am so mad\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9eg_VGexf4i",
        "outputId": "fc34afaa-b71a-40e4-c195-7782b39910a6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Bro I am so mad [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I love you\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmDXnBMJxkae",
        "outputId": "21ee8b5b-16ce-4b08-eb32-6dce2879d7d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "I love you [':two_hearts:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"LMAO\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1AkADrBxpGC",
        "outputId": "b6c5c4a0-cdc0-4a75-ac77-a52f1215c029"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n",
            "LMAO [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 5: Baseline with sentiment"
      ],
      "metadata": {
        "id": "DxVsofm38i8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2[['text', 'Sentiment']], df2['emoji'], test_size=0.2, random_state=42)\n",
        "\n",
        "valid_indices = X_train['text'].notna() & y_train.notna()\n",
        "X_train = X_train[valid_indices]\n",
        "y_train = y_train[valid_indices]\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train['text'])\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train['text'])\n",
        "X_train_padded = tf.keras.preprocessing.sequence.pad_sequences(X_train_sequences, maxlen=10)\n",
        "\n",
        "X_train_sentiment = X_train['Sentiment'].values.reshape(-1, 1)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "encoded_labels = label_encoder.transform(y_train)\n",
        "y_train_categorical = tf.keras.utils.to_categorical(encoded_labels, num_classes=len(np.unique(y_train)))\n",
        "\n",
        "\n",
        "text_input = Input(shape=(10,), dtype='int32', name='text_input')\n",
        "text_features = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8, input_length=10)(text_input)\n",
        "text_features = Flatten()(text_features)\n",
        "\n",
        "sentiment_input = Input(shape=(1,), dtype='float32', name='sentiment_input')\n",
        "sentiment_features = Dense(8, activation='relu')(sentiment_input)\n",
        "\n",
        "concatenated_features = concatenate([text_features, sentiment_features])\n",
        "\n",
        "output = Dense(len(np.unique(y_train)), activation='softmax')(concatenated_features)\n",
        "\n",
        "model = Model(inputs=[text_input, sentiment_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVs1Z0Gl8vxH",
        "outputId": "cbff06cc-468b-4f8c-cd7f-d9e35aedd6c4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_input (InputLayer)     [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 10, 8)                1755104   ['text_input[0][0]']          \n",
            "                                                                                                  \n",
            " sentiment_input (InputLaye  [(None, 1)]                  0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 80)                   0         ['embedding_3[0][0]']         \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 8)                    16        ['sentiment_input[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 88)                   0         ['flatten_1[0][0]',           \n",
            " )                                                                   'dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 48)                   4272      ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1759392 (6.71 MB)\n",
            "Trainable params: 1759392 (6.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([X_train_padded, X_train_sentiment], y_train_categorical, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcWKWUXP-Z13",
        "outputId": "c483597c-4166-451c-f434-028c164f518e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30213/30213 [==============================] - 138s 5ms/step - loss: 2.6084 - accuracy: 0.3432 - val_loss: 2.4604 - val_accuracy: 0.3759\n",
            "Epoch 2/10\n",
            "30213/30213 [==============================] - 125s 4ms/step - loss: 2.3795 - accuracy: 0.3951 - val_loss: 2.4140 - val_accuracy: 0.3917\n",
            "Epoch 3/10\n",
            "30213/30213 [==============================] - 130s 4ms/step - loss: 2.3056 - accuracy: 0.4135 - val_loss: 2.4043 - val_accuracy: 0.3972\n",
            "Epoch 4/10\n",
            "30213/30213 [==============================] - 125s 4ms/step - loss: 2.2597 - accuracy: 0.4256 - val_loss: 2.4052 - val_accuracy: 0.4001\n",
            "Epoch 5/10\n",
            "30213/30213 [==============================] - 123s 4ms/step - loss: 2.2264 - accuracy: 0.4343 - val_loss: 2.4105 - val_accuracy: 0.4009\n",
            "Epoch 6/10\n",
            "30213/30213 [==============================] - 127s 4ms/step - loss: 2.2002 - accuracy: 0.4417 - val_loss: 2.4165 - val_accuracy: 0.4019\n",
            "Epoch 7/10\n",
            "30213/30213 [==============================] - 124s 4ms/step - loss: 2.1788 - accuracy: 0.4476 - val_loss: 2.4222 - val_accuracy: 0.4024\n",
            "Epoch 8/10\n",
            "30213/30213 [==============================] - 124s 4ms/step - loss: 2.1606 - accuracy: 0.4532 - val_loss: 2.4297 - val_accuracy: 0.4037\n",
            "Epoch 9/10\n",
            "30213/30213 [==============================] - 126s 4ms/step - loss: 2.1451 - accuracy: 0.4574 - val_loss: 2.4366 - val_accuracy: 0.4027\n",
            "Epoch 10/10\n",
            "30213/30213 [==============================] - 130s 4ms/step - loss: 2.1318 - accuracy: 0.4609 - val_loss: 2.4424 - val_accuracy: 0.4036\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef593500910>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing model 5"
      ],
      "metadata": {
        "id": "HTAf14tWml8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "min_length = min(len(true_classes), len(predicted_classes))\n",
        "true_classes = true_classes[:min_length]\n",
        "predicted_classes = predicted_classes[:min_length]\n",
        "\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='weighted')\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYVqe3YDEe84",
        "outputId": "af41ae6a-bb23-4bc1-8a83-5a9f0a70d9d8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.1943\n",
            "Precision: 0.1294\n",
            "Recall: 0.1943\n",
            "F1 Score: 0.1472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"yay\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkflcqO9RRIH",
        "outputId": "3abf2fae-5193-459d-a32d-667a6d3895a6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "yay [':smiling_face_with_smiling_eyes:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I am so happy\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtPpvP5FRYlN",
        "outputId": "35f9574c-7cd7-4794-913f-9923f469e71a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "I am so happy [':loudly_crying_face:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"Bro I am so mad\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVr1fdMZRbYI",
        "outputId": "5002abf6-1afd-4e69-b3d3-c500261b21d9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "Bro I am so mad [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"I love you\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J6QOvJXRgnc",
        "outputId": "126b533a-1b8a-4ff2-b060-7e1b22b012af"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 80ms/step\n",
            "I love you [':red_heart:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = \"LMAO\"\n",
        "sentiment_value = get_sentiment(random_sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences([random_sentence])\n",
        "padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=10)\n",
        "sentiment_input = np.array([sentiment_value]).reshape(1, -1)\n",
        "\n",
        "\n",
        "prediction = model.predict([padded_sequence, sentiment_input])\n",
        "predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "predicted_label = label_encoder.inverse_transform([predicted_index])\n",
        "print(random_sentence, predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU9TvmVeRk-D",
        "outputId": "9bdbc4d6-847b-46eb-b063-e932cc92ed02"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "LMAO [':face_with_tears_of_joy:']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}